{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exploring the BAM file format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pysam \n",
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read BAM file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AlignmentFile(filepath_or_object, mode=None, template=None,\n",
      "    reference_names=None, reference_lengths=None, text=NULL,\n",
      "    header=None, add_sq_text=False, check_header=True, check_sq=True,\n",
      "    reference_filename=None, filename=None, index_filename=None,\n",
      "    filepath_index=None, require_index=False, duplicate_filehandle=True,\n",
      "    ignore_truncation=False, threads=1)\n",
      "\n",
      "    A :term:`SAM`/:term:`BAM`/:term:`CRAM` formatted file.\n",
      "\n",
      "    If `filepath_or_object` is a string, the file is automatically\n",
      "    opened. If `filepath_or_object` is a python File object, the\n",
      "    already opened file will be used.\n",
      "\n",
      "    If the file is opened for reading and an index exists (if file is BAM, a\n",
      "    .bai file or if CRAM a .crai file), it will be opened automatically.\n",
      "    `index_filename` may be specified explicitly. If the index is not named\n",
      "    in the standard manner, not located in the same directory as the\n",
      "    BAM/CRAM file, or is remote.  Without an index, random access via\n",
      "    :meth:`~pysam.AlignmentFile.fetch` and :meth:`~pysam.AlignmentFile.pileup`\n",
      "    is disabled.\n",
      "\n",
      "    For writing, the header of a :term:`SAM` file/:term:`BAM` file can\n",
      "    be constituted from several sources (see also the samtools format\n",
      "    specification):\n",
      "\n",
      "        1. If `template` is given, the header is copied from another\n",
      "           `AlignmentFile` (`template` must be a\n",
      "           :class:`~pysam.AlignmentFile`).\n",
      "\n",
      "        2. If `header` is given, the header is built from a\n",
      "           multi-level dictionary.\n",
      "\n",
      "        3. If `text` is given, new header text is copied from raw\n",
      "           text.\n",
      "\n",
      "        4. The names (`reference_names`) and lengths\n",
      "           (`reference_lengths`) are supplied directly as lists.\n",
      "\n",
      "    When reading or writing a CRAM file, the filename of a FASTA-formatted\n",
      "    reference can be specified with `reference_filename`.\n",
      "\n",
      "    By default, if a file is opened in mode 'r', it is checked\n",
      "    for a valid header (`check_header` = True) and a definition of\n",
      "    chromosome names (`check_sq` = True).\n",
      "\n",
      "    Parameters\n",
      "    ----------\n",
      "    mode : string\n",
      "        `mode` should be ``r`` for reading or ``w`` for writing. The\n",
      "        default is text mode (:term:`SAM`). For binary (:term:`BAM`)\n",
      "        I/O you should append ``b`` for compressed or ``u`` for\n",
      "        uncompressed :term:`BAM` output.  Use ``h`` to output header\n",
      "        information in text (:term:`TAM`) mode. Use ``c`` for\n",
      "        :term:`CRAM` formatted files.\n",
      "\n",
      "        If ``b`` is present, it must immediately follow ``r`` or\n",
      "        ``w``.  Valid modes are ``r``, ``w``, ``wh``, ``rb``, ``wb``,\n",
      "        ``wbu``, ``wb0``, ``rc`` and ``wc``. For instance, to open a\n",
      "        :term:`BAM` formatted file for reading, type::\n",
      "\n",
      "           f = pysam.AlignmentFile('ex1.bam','rb')\n",
      "\n",
      "        If mode is not specified, the method will try to auto-detect\n",
      "        in the order 'rb', 'r', thus both the following should work::\n",
      "\n",
      "            f1 = pysam.AlignmentFile('ex1.bam')\n",
      "            f2 = pysam.AlignmentFile('ex1.sam')\n",
      "\n",
      "    template : AlignmentFile\n",
      "        when writing, copy header from file `template`.\n",
      "\n",
      "    header :  dict or AlignmentHeader\n",
      "        when writing, build header from a multi-level dictionary. The\n",
      "        first level are the four types ('HD', 'SQ', ...). The second\n",
      "        level are a list of lines, with each line being a list of\n",
      "        tag-value pairs. The header is constructed first from all the\n",
      "        defined fields, followed by user tags in alphabetical\n",
      "        order. Alternatively, an :class:`~pysam.AlignmentHeader`\n",
      "        object can be passed directly.\n",
      "\n",
      "    text : string\n",
      "        when writing, use the string provided as the header\n",
      "\n",
      "    reference_names : list\n",
      "        see reference_lengths\n",
      "\n",
      "    reference_lengths : list\n",
      "        when writing or opening a SAM file without header build header\n",
      "        from list of chromosome names and lengths.  By default, 'SQ'\n",
      "        and 'LN' tags will be added to the header text. This option\n",
      "        can be changed by unsetting the flag `add_sq_text`.\n",
      "\n",
      "    add_sq_text : bool\n",
      "        do not add 'SQ' and 'LN' tags to header. This option permits\n",
      "        construction :term:`SAM` formatted files without a header.\n",
      "\n",
      "    add_sam_header : bool\n",
      "        when outputting SAM the default is to output a header. This is\n",
      "        equivalent to opening the file in 'wh' mode. If this option is\n",
      "        set to False, no header will be output. To read such a file,\n",
      "        set `check_header=False`.\n",
      "\n",
      "    check_header : bool\n",
      "        obsolete: when reading a SAM file, check if header is present\n",
      "        (default=True)\n",
      "\n",
      "    check_sq : bool\n",
      "        when reading, check if SQ entries are present in header\n",
      "        (default=True)\n",
      "\n",
      "    reference_filename : string\n",
      "        Path to a FASTA-formatted reference file. Valid only for CRAM files.\n",
      "        When reading a CRAM file, this overrides both ``$REF_PATH`` and the URL\n",
      "        specified in the header (``UR`` tag), which are normally used to find\n",
      "        the reference.\n",
      "\n",
      "    index_filename : string\n",
      "        Explicit path to the index file.  Only needed if the index is not\n",
      "        named in the standard manner, not located in the same directory as\n",
      "        the BAM/CRAM file, or is remote.  An IOError is raised if the index\n",
      "        cannot be found or is invalid.\n",
      "\n",
      "    filepath_index : string\n",
      "        Alias for `index_filename`.\n",
      "\n",
      "    require_index : bool\n",
      "        When reading, require that an index file is present and is valid or\n",
      "        raise an IOError.  (default=False)\n",
      "\n",
      "    filename : string\n",
      "        Alternative to filepath_or_object. Filename of the file\n",
      "        to be opened.\n",
      "\n",
      "    duplicate_filehandle: bool\n",
      "        By default, file handles passed either directly or through\n",
      "        File-like objects will be duplicated before passing them to\n",
      "        htslib. The duplication prevents issues where the same stream\n",
      "        will be closed by htslib and through destruction of the\n",
      "        high-level python object. Set to False to turn off\n",
      "        duplication.\n",
      "\n",
      "    ignore_truncation: bool\n",
      "        Issue a warning, instead of raising an error if the current file\n",
      "        appears to be truncated due to a missing EOF marker.  Only applies\n",
      "        to bgzipped formats. (Default=False)\n",
      "\n",
      "    format_options: list\n",
      "        A list of key=value strings, as accepted by --input-fmt-option and\n",
      "        --output-fmt-option in samtools.\n",
      "    threads: integer\n",
      "        Number of threads to use for compressing/decompressing BAM/CRAM files.\n",
      "        Setting threads to > 1 cannot be combined with `ignore_truncation`.\n",
      "        (Default=1)\n",
      "    \n"
     ]
    }
   ],
   "source": [
    "file = pysam.AlignmentFile(\"./Oligo_1.bam\", \"rb\")\n",
    "print(file.__doc__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "01670043-4149-45e8-882b-4d25ad62ee56\t0\t#0\t9\t3\t13M1D13M1D21M3I2M1D37M\t*\t0\t0\tGATAGGTAGGACTTTTAGCTAGTGAACCTAGCCTCCGGAGACAGGTCGTAGCACCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAT\tarray('B', [7, 5, 10, 3, 7, 6, 4, 1, 5, 3, 3, 6, 4, 19, 12, 23, 18, 32, 27, 33, 9, 19, 30, 31, 26, 24, 13, 9, 14, 19, 15, 22, 15, 21, 34, 25, 30, 33, 24, 26, 29, 11, 22, 21, 29, 19, 16, 25, 12, 4, 4, 4, 5, 18, 16, 19, 22, 21, 14, 23, 20, 27, 23, 24, 26, 6, 23, 21, 28, 21, 22, 22, 22, 35, 18, 34, 21, 29, 14, 15, 12, 15, 16, 17, 19, 20, 19, 20, 17])\t[('NM', 9), ('ms', 102), ('AS', 98), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.07779999822378159), ('rl', 0)]\n",
      "da8d2631-2eab-4c2a-8664-a792b09524e8\t0\t#0\t10\t3\t89M\t*\t0\t0\tGTAGATAGGACTCTTTAGCTAGTGAACCACAGCCTCCGGAGACAGGTCGCGGCCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAAT\tarray('B', [3, 1, 15, 25, 28, 30, 17, 26, 20, 17, 8, 7, 13, 14, 4, 23, 24, 26, 27, 22, 8, 18, 21, 20, 16, 14, 14, 21, 4, 16, 17, 24, 21, 16, 17, 25, 22, 24, 31, 25, 16, 27, 23, 17, 8, 13, 13, 11, 14, 2, 6, 5, 11, 20, 23, 26, 28, 33, 26, 25, 23, 28, 26, 14, 18, 29, 23, 13, 24, 24, 24, 25, 37, 18, 25, 19, 28, 16, 14, 12, 13, 13, 10, 10, 10, 9, 9, 8, 8])\t[('NM', 5), ('ms', 144), ('AS', 144), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.05620000138878822), ('rl', 0)]\n",
      "4f783908-603c-4a5a-adbf-e7aaf7d6e28e\t0\t#0\t10\t3\t11M3I19M1D18M1I39M\t*\t0\t0\tAGAGATAGGACATTTCTTTAGCTAGTGAACCCTGCCTCCGGAGACAGGTCGTTGTCCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAA\tarray('B', [4, 6, 23, 24, 24, 11, 22, 21, 20, 5, 11, 8, 10, 10, 11, 3, 9, 21, 23, 26, 34, 29, 28, 20, 20, 25, 31, 23, 25, 21, 23, 13, 20, 6, 10, 11, 5, 5, 3, 7, 7, 13, 24, 23, 25, 23, 27, 27, 19, 4, 4, 10, 14, 12, 2, 17, 14, 16, 13, 12, 24, 18, 22, 20, 32, 33, 35, 31, 16, 9, 20, 24, 24, 19, 20, 20, 14, 23, 10, 8, 4, 1, 2, 4, 4, 4, 5, 5, 5, 5, 4])\t[('NM', 8), ('ms', 108), ('AS', 104), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.06669999659061432), ('rl', 0)]\n",
      "a7b7ef0e-63d7-4431-87a1-6b10c4b9b3c8\t0\t#0\t10\t10\t19M1D52M1I13M5S\t*\t0\t0\tAGAGATAGGACTCTCTAGCATTGAACCCCAGCCTCCGGAGACAGGTCGCGACCTGTGTAGATGAGAGAACTGGAGTGCACAAAAACTAAA\tarray('B', [13, 17, 12, 17, 10, 7, 7, 19, 20, 30, 26, 9, 9, 12, 4, 12, 23, 22, 24, 7, 5, 14, 18, 16, 14, 13, 15, 4, 8, 20, 18, 14, 10, 6, 12, 11, 12, 12, 22, 25, 25, 33, 30, 27, 27, 13, 8, 22, 4, 10, 6, 9, 14, 15, 11, 9, 14, 8, 11, 8, 9, 3, 8, 11, 27, 28, 25, 21, 22, 21, 15, 20, 12, 4, 22, 19, 25, 11, 12, 15, 14, 15, 17, 14, 5, 6, 6, 5, 3, 2])\t[('NM', 6), ('ms', 106), ('AS', 106), ('nn', 0), ('tp', 'P'), ('cm', 4), ('s1', 32), ('s2', 0), ('de', 0.0697999969124794), ('rl', 0)]\n",
      "c488610d-d7a4-4d59-9299-5c92d6652a09\t0\t#0\t11\t20\t38M2I12M1I37M\t*\t0\t0\tCAGATAGGACTCTTTAGCTAGTGAACCCTAGCCCACAGAAAGACAGGTCGTGCACCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAT\tarray('B', [3, 3, 5, 4, 4, 11, 16, 16, 16, 10, 5, 8, 9, 19, 25, 25, 30, 27, 28, 19, 22, 15, 12, 16, 16, 13, 10, 4, 11, 16, 22, 15, 9, 4, 4, 3, 3, 7, 3, 3, 8, 21, 22, 15, 6, 19, 26, 27, 23, 23, 14, 12, 2, 2, 14, 12, 15, 21, 23, 27, 16, 26, 27, 32, 32, 30, 7, 12, 20, 20, 21, 21, 19, 16, 16, 20, 23, 18, 24, 15, 14, 14, 8, 7, 7, 6, 6, 5, 4, 2])\t[('NM', 9), ('ms', 102), ('AS', 100), ('nn', 0), ('tp', 'P'), ('cm', 3), ('s1', 48), ('s2', 0), ('de', 0.08990000188350677), ('rl', 0)]\n",
      "b309b891-99c3-4ef1-afb0-4488d7aa2a6b\t0\t#0\t11\t2\t28M2D20M1I39M\t*\t0\t0\tGAGATAGGACTCTTTAGCTGCTGAACCCACCTCCGGAGACAGGTCGTGCTCCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAAAT\tarray('B', [6, 7, 19, 7, 6, 7, 12, 18, 14, 5, 5, 4, 5, 6, 11, 17, 6, 9, 7, 3, 5, 22, 23, 23, 21, 21, 19, 15, 3, 5, 12, 3, 7, 3, 19, 25, 26, 21, 34, 33, 38, 26, 22, 14, 3, 14, 19, 23, 4, 4, 13, 14, 16, 21, 24, 15, 9, 8, 27, 28, 28, 37, 23, 39, 12, 26, 21, 21, 21, 21, 26, 16, 25, 15, 24, 6, 6, 6, 6, 5, 5, 5, 6, 6, 6, 5, 4, 4])\t[('NM', 10), ('ms', 92), ('AS', 90), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.10109999775886536), ('rl', 0)]\n",
      "e86af11e-1562-4de3-ae06-b9a522d7e65f\t0\t#0\t11\t20\t34M1D11M3D1M1I34M68S\t*\t0\t0\tGAGATAGGACTCTTTAGCTAGTGAACCCTAGCCTCAGAGACAGGTGTTCCTGTGTAGATGAGAGAACTGAGTGCACAAAAATTCCCACCCATCCACATCATCACTCCCACTATATATTTATATTATCCGTCCATACAAACATCCTAATT\tarray('B', [1, 3, 9, 5, 8, 10, 11, 9, 11, 5, 4, 3, 15, 21, 24, 31, 36, 38, 32, 17, 24, 23, 18, 26, 12, 30, 33, 21, 21, 31, 19, 18, 5, 5, 23, 11, 29, 20, 33, 31, 36, 37, 25, 25, 9, 16, 11, 11, 16, 18, 18, 21, 23, 32, 14, 20, 26, 23, 25, 15, 7, 24, 23, 14, 16, 17, 15, 19, 28, 20, 35, 17, 19, 5, 7, 8, 8, 8, 8, 7, 9, 4, 5, 11, 11, 10, 2, 8, 8, 7, 5, 3, 2, 8, 1, 2, 2, 3, 3, 3, 3, 1, 2, 1, 4, 13, 14, 17, 5, 12, 21, 19, 17, 15, 7, 5, 4, 9, 23, 21, 15, 15, 20, 19, 22, 3, 5, 2, 1, 2, 3, 3, 3, 2, 1, 4, 13, 10, 9, 9, 6, 3, 14, 12, 13, 13, 11, 13, 10])\t[('NM', 8), ('ms', 96), ('AS', 92), ('nn', 0), ('tp', 'P'), ('cm', 3), ('s1', 48), ('s2', 0), ('de', 0.0723000019788742), ('rl', 0)]\n",
      "f81c3f69-53b2-452b-9c62-fb262bc898bb\t0\t#0\t11\t2\t25M2D5M1I18M1I33M69S\t*\t0\t0\tGAGATAGGACTCTTTAGCTAGTGAACTTGCACCACGGAGACAGGTCGTGTTCCTGTGTAGATGAGAGAACTGAGTGCACAAAATACCCACCCATCCTCATATATCCTATATCATCCATTACTTCATCCCTCCATCCATCCCTATTTCCTAAT\tarray('B', [4, 10, 19, 15, 21, 8, 26, 25, 25, 17, 5, 5, 15, 21, 23, 26, 20, 19, 34, 29, 27, 25, 28, 12, 3, 8, 5, 4, 7, 10, 6, 5, 6, 1, 3, 4, 31, 24, 29, 25, 23, 31, 23, 31, 20, 18, 17, 5, 7, 5, 5, 13, 9, 9, 13, 11, 13, 3, 6, 19, 25, 25, 20, 14, 15, 26, 23, 20, 19, 20, 20, 29, 24, 23, 27, 29, 6, 14, 15, 14, 14, 12, 12, 12, 3, 6, 5, 12, 11, 20, 19, 6, 5, 7, 5, 9, 2, 8, 2, 2, 6, 2, 3, 3, 13, 18, 13, 10, 10, 2, 3, 3, 4, 5, 14, 11, 8, 6, 5, 4, 3, 7, 8, 5, 6, 3, 11, 11, 6, 2, 6, 7, 6, 3, 6, 4, 2, 2, 2, 4, 3, 1, 3, 6, 4, 4, 16, 9, 13, 12, 14, 5])\t[('NM', 10), ('ms', 68), ('AS', 66), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.1071000024676323), ('rl', 0)]\n",
      "8b712abd-a6bd-4394-9c24-9f0500658800\t0\t#0\t11\t31\t18M1I66M63S\t*\t0\t0\tGAGATAGGACTCTTTAGCTTAGTGAACCCTAGCCTCCGGAGACAGGTCGTGGCCTGTGTAGATGAGAGAACTGAGTGCACAAAAATCCCTCCTCCCTACCCCATAACCCTATTATCATTCATATTAACGCCCACCGTCCAATCACCTA\tarray('B', [3, 6, 18, 17, 20, 19, 26, 29, 28, 10, 9, 26, 25, 11, 30, 28, 22, 11, 5, 4, 9, 24, 29, 27, 26, 13, 20, 20, 12, 13, 14, 17, 20, 17, 9, 19, 17, 26, 23, 20, 26, 26, 24, 13, 18, 32, 20, 16, 4, 4, 12, 5, 7, 16, 16, 30, 31, 30, 21, 22, 26, 29, 28, 24, 23, 32, 21, 23, 24, 22, 27, 28, 21, 15, 27, 19, 29, 12, 13, 13, 13, 13, 13, 12, 3, 11, 16, 16, 16, 3, 4, 4, 9, 15, 17, 16, 10, 2, 6, 7, 9, 7, 2, 4, 8, 7, 5, 13, 22, 25, 20, 18, 19, 11, 15, 2, 4, 8, 14, 8, 15, 8, 4, 10, 10, 8, 3, 5, 5, 6, 10, 6, 1, 4, 3, 1, 2, 4, 1, 3, 2, 7, 3, 2, 11, 5, 8, 3])\t[('NM', 4), ('ms', 132), ('AS', 132), ('nn', 0), ('tp', 'P'), ('cm', 4), ('s1', 50), ('s2', 0), ('de', 0.0471000000834465), ('rl', 0)]\n",
      "a7a21875-5baf-4971-9318-dff6f4c24ab8\t0\t#0\t11\t2\t11M1D20M1I2M1D15M1I33M75S\t*\t0\t0\tCAGATAGGACTTTTAGCTAGTGAACCCTAGCACTCGGAGACAGGTCGTGCTCCTGTGTAGATGAGAGAACTGAGTGCACAAAATTCCCACCCATCCCAACATGCCCTATATCATATCCATACTTCATCCATGCCCTCCATCCGCCAACCATCCTAAAC\tarray('B', [1, 8, 12, 11, 11, 18, 21, 24, 13, 10, 5, 14, 22, 28, 25, 21, 16, 28, 23, 12, 8, 21, 12, 9, 8, 12, 4, 4, 7, 10, 10, 3, 3, 1, 7, 8, 17, 28, 29, 31, 29, 21, 29, 30, 32, 21, 29, 21, 8, 5, 3, 20, 18, 20, 25, 29, 32, 16, 24, 29, 26, 21, 9, 24, 21, 5, 23, 19, 19, 19, 19, 22, 20, 17, 16, 27, 24, 3, 12, 23, 24, 17, 13, 8, 7, 6, 6, 7, 1, 9, 12, 18, 17, 12, 10, 9, 11, 10, 7, 6, 6, 3, 1, 4, 10, 9, 6, 8, 9, 11, 10, 9, 9, 3, 9, 4, 12, 15, 17, 10, 1, 2, 12, 15, 13, 12, 10, 6, 8, 5, 3, 1, 4, 5, 7, 2, 7, 18, 17, 11, 3, 6, 3, 8, 9, 6, 5, 5, 4, 6, 5, 15, 18, 14, 15, 9, 4, 3])\t[('NM', 7), ('ms', 84), ('AS', 84), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.08240000158548355), ('rl', 0)]\n",
      "\n",
      "\n",
      "01670043-4149-45e8-882b-4d25ad62ee56\t0\t#0\t9\t3\t13M1D13M1D21M3I2M1D37M\t*\t0\t0\tGATAGGTAGGACTTTTAGCTAGTGAACCTAGCCTCCGGAGACAGGTCGTAGCACCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAT\tarray('B', [7, 5, 10, 3, 7, 6, 4, 1, 5, 3, 3, 6, 4, 19, 12, 23, 18, 32, 27, 33, 9, 19, 30, 31, 26, 24, 13, 9, 14, 19, 15, 22, 15, 21, 34, 25, 30, 33, 24, 26, 29, 11, 22, 21, 29, 19, 16, 25, 12, 4, 4, 4, 5, 18, 16, 19, 22, 21, 14, 23, 20, 27, 23, 24, 26, 6, 23, 21, 28, 21, 22, 22, 22, 35, 18, 34, 21, 29, 14, 15, 12, 15, 16, 17, 19, 20, 19, 20, 17])\t[('NM', 9), ('ms', 102), ('AS', 98), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.07779999822378159), ('rl', 0)]\n",
      "da8d2631-2eab-4c2a-8664-a792b09524e8\t0\t#0\t10\t3\t89M\t*\t0\t0\tGTAGATAGGACTCTTTAGCTAGTGAACCACAGCCTCCGGAGACAGGTCGCGGCCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAAT\tarray('B', [3, 1, 15, 25, 28, 30, 17, 26, 20, 17, 8, 7, 13, 14, 4, 23, 24, 26, 27, 22, 8, 18, 21, 20, 16, 14, 14, 21, 4, 16, 17, 24, 21, 16, 17, 25, 22, 24, 31, 25, 16, 27, 23, 17, 8, 13, 13, 11, 14, 2, 6, 5, 11, 20, 23, 26, 28, 33, 26, 25, 23, 28, 26, 14, 18, 29, 23, 13, 24, 24, 24, 25, 37, 18, 25, 19, 28, 16, 14, 12, 13, 13, 10, 10, 10, 9, 9, 8, 8])\t[('NM', 5), ('ms', 144), ('AS', 144), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.05620000138878822), ('rl', 0)]\n",
      "4f783908-603c-4a5a-adbf-e7aaf7d6e28e\t0\t#0\t10\t3\t11M3I19M1D18M1I39M\t*\t0\t0\tAGAGATAGGACATTTCTTTAGCTAGTGAACCCTGCCTCCGGAGACAGGTCGTTGTCCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAA\tarray('B', [4, 6, 23, 24, 24, 11, 22, 21, 20, 5, 11, 8, 10, 10, 11, 3, 9, 21, 23, 26, 34, 29, 28, 20, 20, 25, 31, 23, 25, 21, 23, 13, 20, 6, 10, 11, 5, 5, 3, 7, 7, 13, 24, 23, 25, 23, 27, 27, 19, 4, 4, 10, 14, 12, 2, 17, 14, 16, 13, 12, 24, 18, 22, 20, 32, 33, 35, 31, 16, 9, 20, 24, 24, 19, 20, 20, 14, 23, 10, 8, 4, 1, 2, 4, 4, 4, 5, 5, 5, 5, 4])\t[('NM', 8), ('ms', 108), ('AS', 104), ('nn', 0), ('tp', 'P'), ('cm', 2), ('s1', 28), ('s2', 0), ('de', 0.06669999659061432), ('rl', 0)]\n",
      "a7b7ef0e-63d7-4431-87a1-6b10c4b9b3c8\t0\t#0\t10\t10\t19M1D52M1I13M5S\t*\t0\t0\tAGAGATAGGACTCTCTAGCATTGAACCCCAGCCTCCGGAGACAGGTCGCGACCTGTGTAGATGAGAGAACTGGAGTGCACAAAAACTAAA\tarray('B', [13, 17, 12, 17, 10, 7, 7, 19, 20, 30, 26, 9, 9, 12, 4, 12, 23, 22, 24, 7, 5, 14, 18, 16, 14, 13, 15, 4, 8, 20, 18, 14, 10, 6, 12, 11, 12, 12, 22, 25, 25, 33, 30, 27, 27, 13, 8, 22, 4, 10, 6, 9, 14, 15, 11, 9, 14, 8, 11, 8, 9, 3, 8, 11, 27, 28, 25, 21, 22, 21, 15, 20, 12, 4, 22, 19, 25, 11, 12, 15, 14, 15, 17, 14, 5, 6, 6, 5, 3, 2])\t[('NM', 6), ('ms', 106), ('AS', 106), ('nn', 0), ('tp', 'P'), ('cm', 4), ('s1', 32), ('s2', 0), ('de', 0.0697999969124794), ('rl', 0)]\n"
     ]
    }
   ],
   "source": [
    "# get all reads (just printing the first 10 here)\n",
    "i = 0\n",
    "for read in file:\n",
    "    print(read)\n",
    "    i +=1 \n",
    "    if i >= 10: break\n",
    "\n",
    "print(\"\\n\")\n",
    "\n",
    "# get read from a specific region\n",
    "for read in file.fetch(\"oligo\", 9, 10):\n",
    "    print(read)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One line of a bam file corresponds to one read. It contains the following information:\n",
    "\n",
    "\n",
    "1. **Query template NAME**: 88db3006-33a2-4019-b61b-000d67075abc\n",
    "2. **bitwise FLAG**: 0 \n",
    "3. **References sequence NAME**: oligo\n",
    "4. **1- based leftmost mapping POSition**: 20\n",
    "5. **MAPping Quality**: 60\n",
    "6. **CIGAR string**: 6S22M1D56M     (https://genome.sph.umich.edu/wiki/SAM#What_is_a_CIGAR?)\n",
    "7. **Ref. name of the mate/next read**: *       \n",
    "8. **Position of the mate/next read**: 0       \n",
    "9. **observed Template LENgth**: 0       \n",
    "10. **segment SEQuence**: GATGGGCTCTTTAGCTAGTGAACCCTAGCACAGGAGACAGGTCGCGACCTGTGTAGATGAGAGAACTGAGTGCACAAAAAAAAT        \n",
    "11. **ASCII of Phred-scaled base QUALity+33**: $$&*85+%%73;??82+16<2./7.,#(''*'428'%4=892/&#8682292@20?::63@6799995-545102011111-,,\n",
    "12. **optional fields**: NM:i:4  ms:i:120   AS:i:120 nn:i:0  tp:A:P  cm:i:7  s1:i:68 s2:i:0  de:f:0.0506     rl:i:0\n",
    "\n",
    "taken from https://samtools.github.io/hts-specs/SAMv1.pdf\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pileup format"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pileup file was created using Samtools mpileup command:\n",
    "\n",
    "```samtools mpileup -f Oligo_ref.fa -A -d 0 -Q 0 Oligo_1.bam > Oligo_1_a.pileup``` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>chr name</th>\n",
       "      <th>position</th>\n",
       "      <th>ref base</th>\n",
       "      <th>num reads</th>\n",
       "      <th>read bases</th>\n",
       "      <th>base qualities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>oligo</td>\n",
       "      <td>9</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>*</td>\n",
       "      <td>*</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>oligo</td>\n",
       "      <td>10</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>^+.</td>\n",
       "      <td>.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>oligo</td>\n",
       "      <td>11</td>\n",
       "      <td>T</td>\n",
       "      <td>1</td>\n",
       "      <td>G</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>oligo</td>\n",
       "      <td>12</td>\n",
       "      <td>A</td>\n",
       "      <td>249</td>\n",
       "      <td>......^+.^#.^$.^$.^#.^+.^#.^+.^$.^+.^#.^+.^,.^...</td>\n",
       "      <td>08002:././././.../.....//1././/.0././/.//.//.....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>oligo</td>\n",
       "      <td>13</td>\n",
       "      <td>G</td>\n",
       "      <td>2713</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>:9244352./4253244436/5&lt;46103115/102:1:74167255...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>oligo</td>\n",
       "      <td>14</td>\n",
       "      <td>A</td>\n",
       "      <td>3528</td>\n",
       "      <td>............................................+1...</td>\n",
       "      <td>=902.941219813902&lt;159573925:..?5&lt;2/6:62.54&gt;172...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>oligo</td>\n",
       "      <td>15</td>\n",
       "      <td>T</td>\n",
       "      <td>2711</td>\n",
       "      <td>........................-1A.............-1A......</td>\n",
       "      <td>?654&lt;18417902.029:26372@6:6.:307:2621202241;86...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>oligo</td>\n",
       "      <td>16</td>\n",
       "      <td>A</td>\n",
       "      <td>2017</td>\n",
       "      <td>.......................*.*...............*.......</td>\n",
       "      <td>27435374=1:?1;;;35;&lt;=105;1.50768016/1/18.;&lt;010...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>oligo</td>\n",
       "      <td>17</td>\n",
       "      <td>G</td>\n",
       "      <td>5683</td>\n",
       "      <td>.................................................</td>\n",
       "      <td>;641;;6702.;9@94D/=45?&gt;1?A&lt;&gt;470A.5.;03;.&gt;82509...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>oligo</td>\n",
       "      <td>18</td>\n",
       "      <td>G</td>\n",
       "      <td>4752</td>\n",
       "      <td>......................................-1A........</td>\n",
       "      <td>55513:&gt;98@58?038/?2&lt;??09A&lt;907893.764660554.676...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  chr name  position ref base  num reads  \\\n",
       "0    oligo         9        C          0   \n",
       "1    oligo        10        A          1   \n",
       "2    oligo        11        T          1   \n",
       "3    oligo        12        A        249   \n",
       "4    oligo        13        G       2713   \n",
       "5    oligo        14        A       3528   \n",
       "6    oligo        15        T       2711   \n",
       "7    oligo        16        A       2017   \n",
       "8    oligo        17        G       5683   \n",
       "9    oligo        18        G       4752   \n",
       "\n",
       "                                          read bases  \\\n",
       "0                                                  *   \n",
       "1                                                ^+.   \n",
       "2                                                  G   \n",
       "3  ......^+.^#.^$.^$.^#.^+.^#.^+.^$.^+.^#.^+.^,.^...   \n",
       "4  .................................................   \n",
       "5  ............................................+1...   \n",
       "6  ........................-1A.............-1A......   \n",
       "7  .......................*.*...............*.......   \n",
       "8  .................................................   \n",
       "9  ......................................-1A........   \n",
       "\n",
       "                                      base qualities  \n",
       "0                                                  *  \n",
       "1                                                  .  \n",
       "2                                                  2  \n",
       "3  08002:././././.../.....//1././/.0././/.//.//.....  \n",
       "4  :9244352./4253244436/5<46103115/102:1:74167255...  \n",
       "5  =902.941219813902<159573925:..?5<2/6:62.54>172...  \n",
       "6  ?654<18417902.029:26372@6:6.:307:2621202241;86...  \n",
       "7  27435374=1:?1;;;35;<=105;1.50768016/1/18.;<010...  \n",
       "8  ;641;;6702.;9@94D/=45?>1?A<>470A.5.;03;.>82509...  \n",
       "9  55513:>98@58?038/?2<??09A<907893.764660554.676...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pileup = pd.read_csv(\"./Oligo_1.pileup\", sep = \"\\t\", header = None)\n",
    "pileup.columns = [\"chr name\", \"position\", \"ref base\", \"num reads\", \"read bases\", \"base qualities\"]\n",
    "pileup.head(10)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**read bases** column:\n",
    "- `.`: read matches reference (, on the reverse strand - in this case not so important because I work with RNA data)\n",
    "- `[ACGT]`: read has mismatch a position ([acgt] on the reverse strand)\n",
    "- `^`: first position covered by the read, this is followed by the alignment quality score:\n",
    "    - quality score is given as an ASCII character to transform the character into a Phred quality score, subtract 33 from the the ASCII value.\n",
    "    - For example: ^H corresponds to a reads that start at a given position with a mapping quality of `72(=H) - 33 = 39`\n",
    "- `$`: last position covered by a given read\n",
    "- `\\+[0-9]+[ACGTNacgtn]+` (plus followed by a number and a series of ACGT): denotes insertion\n",
    "    - \\+ corresponds to insertion\n",
    "    - [0-9] corresponds to the lenght of the insertion\n",
    "    - [ACGTNacgtn] corresponds to the inserted sequence (upper case -> forward strand, lower case -> reverse strand) \n",
    "- `\\-[0-9]+[ACGTNacgtn]+`: denotes deletion - same principle as insertion encoding\n",
    "- `>`: denotes reference skip on forward strand (occurs when N is present in a CIGAR string; `<` on reverse strand)\n",
    "- `*`: denotes a deletion where the deleted base(s) are not shown individually (is used if the specific bases of the deletion are not available)\n",
    "\n",
    "\n",
    "**base qualities** column:\n",
    "- each character corresponds to the base quality of a given read at the position\n",
    "- ASCII value corresponds to the quality score (to get Phred score: subtract 33 from ASCII value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "............................................+1T.............................................................................+1T..........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................-1T...............................................................................................................................+1T.............................................................................................................................................................................................................................................-1T..................................................................................................................................................................................................................................................................................................................................................................................................................................+1T.................................................................................................+1T......................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
      "=902.941219813902<159573925:..?5<2/6:62.54>17228620;125581/<:<971?4.=>2./86930450300.//>135219/560933367=184824.873576/7164=466../0392@2//2=8;76//0202=77182</.546660>:/8.:020@/@7=4@753//197209<029=2;663263388198/2658806988556579:3<.6/9/810/1575777<01835362.04389.457>.2/17539:/0.22.6208/331>;;3752/0/0//842414103730B.37;0291=/<8.</53735<874?7223.8583521>1503?059344718<5/8;0:3296;15.747.210/0099>7325.599/9768..2381012016/6<61379..91584;:6<?2<34250639411:158>=4615011/788451:1?.4212>14/6>37.4870/?24=1453..94661010;4/51.564273/>:13::243315305;86;6045..>>269<.6:8.159.7/.3787/2:15074618//1;928<:773=597:9:2546:4//3/68.47/10/1/3804<:2.:=.9<<.089:/102:717//776:8.41@/58<:8812./2//63:86/0159/=129/82/58/570/3C2;480422:9<1.384>3458/4;=874:1>0.5:10>/715/201.83>8D.505741444;953465<223212339.06402.3>4:4<96/.7108=>17;71/82;795;64537<553/1/:.121.0A4?.16/=31752:0417;70/7.60.7171431486:3./.152<2/:2=1/69389501:551553<:/.9757/=14=7>3</28;515276=317A5/.822160<998;8.8750.5:74.22:40..9//:13A6:9.64/3/C</637312.3;22:43255205.2..319=.;074;27;47.625253//.5/67./=3216:1474758036.02.2170/39::.142//?7//9:<=27?2/7051:47//:5./0.;:;./5=37:=/2/78066:0401/53376/6742458<7545488048./99.5967145939532793731/163;01666672669335/>81=7944:/:9<33E:.135;4<463=382/.5218597264@7164236<638.;3=29276009852?965/2/;71/>:172<97<04>2</;.;0.132034564791;09/9@6.B31.::94350/64=94/18=6.0;:/7322?343/543=6<1.1:33141.423465889043A/622=65297;/8737215397/38@3151@4:1@1.7<761.3/4/1.2938092=96/8670<;7:715=63/034688;/;5212;6/;513;1;/4:13610/42146/;/;..85:5@410768.80/.2.46074=<:6660;45358315541;5/5/.20;2146.<09//<8794/43/714A2752934:923/;80793<5:81825514492926;674/68/2./73;201/47/3476.027.550944/2.014<5=:437.5=73841.55/663:944.35..43:7209.8.<0110/429.0<986A975682/>:1.2079:/963:5;8/53.29492;3.=?7182=0A8/0880007162>3727002B20/674.6105;.66258<8/46988414=2:<4984<;251=18>:52/4:=<971087/452;:/14.2?.66<;1..///351?=5.0=/9=;43=.20481447.4213525562093339;:1/720:664379C.6515:22617221>>41./682947:0//.85.3/4<19.<C7@725/:8964/29508;9.:62055@3453101/.034093352689/:6478.244.8.2640657225754=0=26399838471612=2483@029145224=7:0=<8.7;.528.079.743933732=4./747>9@618;792761/82.;.104/.2/35/...2/02/.36253.5.2093359///01/01/64.0.1.//3/.7.03001.3///0/232285147...01/1.20410//503134.3/5/26..5..55.6.5320002530.3203.2/06.//0//3/./0/...1.212/.0012///1342605../.2..0//./5.2650.903121..0525/121.02516....20/3/1.7.0../4/11.50/05/212101.0230233.20212/035..44./3/2.0/1.3.142..4.042/41413420.350..6.4./2/123016.55/.0012000./0./.1:33.3.02720./20..67/..20302/035100.4.2/5/8143/1/1//64/46053/4.16.773/4/1/25410/12.12/07//32120/47110.1.1/40..001014.16823/4.//44./:11./7/1052/1/1/:4/9320.440.//.53203./;/1..//0./250.2../00/.072062///1//.31.65.3/...1....4/12....00303.4..1.2703/25.026.0/1..0/40..233./003215.2/1/50.000.41212/3/300414/202671.723106042.120.4500..19//31.51/32212.601/0//012...36.4/.086/11/84.7../0.:122305.006/10/;/4..312630/1//5/2311.400810//0./00024/31//015/2<//033.032..1/../0.347/02.7.0//2/404/.60061/6.=23000.00/.232..2.11..2..95.93214372010400003//0./8//10.0.1313145/;0/31.15.8.32.4/040.04/42.1.172.2026.7.5/0324211/214.11340.1/0.003.0..6..0././1/06/24/.6602/024/4/4./.4.052./.1/11/2.77..20/1/..//00.2/53/32/.83.003/0102/.4.02..5/6...3//5110417.1/2./22/1042?/1254.568//.1338;//61/31.//./140/.3/10.1/4/69./3/22/2/020/0630.35.0.21//.1.//2211.1.026./2/211./0//3407.23.//5/32226.6//..0/.76..0/124//1200711/06330.22/7/41.40/5264704.9.././13/100.///1261/22/3/0.0/.1.7.052145.03./.170/1400./44././35.2.062/.4032:.1/50690.008200.1103.021005./.4//411141218///.7205<0013.1205//6//0.2./22633.4\n"
     ]
    }
   ],
   "source": [
    "# example read bases string\n",
    "print(pileup.iloc[5, 4])\n",
    "# example base quality string\n",
    "print(pileup.iloc[5,5])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create functions \n",
    "\n",
    "- create function that extracts count (absolute, relative) of each base (A,C,G,T), number of insertions and number of deletions from a given pileup string (->`parse_pileup_string`)\n",
    "- create function that calculates the `mismatch quality sum` (to compare to the coverage allele-fraction threshold) from a given line (-> `calc_mismatch_quality_sum`) "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plan: remove one element after another from the string to extract all needed information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+3AGT\n",
      "-2TT\n",
      "+3ATT\n",
      "+1A\n",
      "[(28, 31), (21, 26), (14, 18), (3, 8)]\n",
      ".C.T.G...C....TT..\n"
     ]
    }
   ],
   "source": [
    "pileup_string = \".C.+3AGTT.G...-2TTC..+3ATT..+1ATT..\"\n",
    "\n",
    "pattern = \"(\\+|\\-)[0-9]+[ACGTNacgtn]+\"\n",
    "coords = []\n",
    "for m in re.finditer(pattern, pileup_string):\n",
    "    str_len = int(pileup_string[m.start(0)+1]) + 1\n",
    "    coords.append((m.start(0), m.start(0)+1+str_len))\n",
    "\n",
    "    print(pileup_string[m.start(0):m.start(0)+1+str_len])\n",
    "\n",
    "print(list(reversed(coords))) # reverse list as to not shift the index downstream\n",
    "\n",
    "for start, end in reversed(coords):\n",
    "    pileup_string = pileup_string[:start] + pileup_string[end:]\n",
    "print(pileup_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_indels(pileup_string: str) -> str:\n",
    "    \"\"\"\n",
    "    Takes a pileup string and removes all occurences of the following patterns:\n",
    "    '\\+[0-9]+[ACGTNacgtn]+' for insertions\n",
    "    '\\-[0-9]+[ACGTNacgtn]+' for deletions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pileup_string : str\n",
    "        Pileup string extracted from the fifth column of a pileup file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Pileup strings with all occurences of the patterns above removed\n",
    "    \"\"\"\n",
    "    pattern = \"(\\+|\\-)[0-9]+[ACGTNacgtn]+\"\n",
    "    \n",
    "    # get the start and end indices of all found patterns \n",
    "    coords = []\n",
    "    for m in re.finditer(pattern, pileup_string):\n",
    "        str_len = int(pileup_string[m.start(0)+1]) + 1\n",
    "        coords.append((m.start(0), m.start(0)+1+str_len))\n",
    "        \n",
    "    # remove the patterns by the indices\n",
    "    for start, end in reversed(coords): # reverse list as to not shift the index downstream\n",
    "        pileup_string = pileup_string[:start] + pileup_string[end:]\n",
    "\n",
    "    return pileup_string\n",
    "\n",
    "\n",
    "def parse_pileup_string(pileup_string: str, ref_base: str) -> dict[int, int, int, int, int, int]:\n",
    "    \"\"\"\n",
    "    Extracts the number of each base called at a given position, as well as the number\n",
    "    of insertions and deletions. Information is extracted from a pileup string (fifth\n",
    "    column in a pileup file).\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    pileup_string : str\n",
    "        Pileup string extracted from the fifth column of a pileup file\n",
    "    ref_base : str\n",
    "        reference base at the position corresponding to the pileup string\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Dictionary containing the number of A, T, C, G, \n",
    "        insertions and deletions.\n",
    "    \"\"\"\n",
    "\n",
    "    pileup_string = pileup_string.lower()\n",
    "    # remove all occurences of a caret and the following letter (could contain a,c,g,t)\n",
    "    pileup_string = re.sub(r'\\^.', '', pileup_string)\n",
    "\n",
    "    ref_base = ref_base.lower()\n",
    "    count_dict = {\"a\": 0, \"t\": 0, \"c\": 0, \"g\": 0, \"ins\": 0, \"del\": 0}\n",
    "\n",
    "    # get number of insertions\n",
    "    count_dict[\"ins\"] = len(re.findall(r'\\+[0-9]+[ACGTNacgtn]+', pileup_string))\n",
    "\n",
    "    # get number of deletions\n",
    "    count_dict[\"del\"] = len(re.findall(r'\\-[0-9]+[ACGTNacgtn]*|\\*', pileup_string))\n",
    "\n",
    "    # remove indel patterns to count the number of mismatches correctly\n",
    "    pileup_string = remove_indels(pileup_string)\n",
    "\n",
    "    # get number of mismatches (i.e. [ACGT])\n",
    "    count_dict[\"a\"] = pileup_string.count(\"a\")\n",
    "    count_dict[\"t\"] = pileup_string.count(\"t\")\n",
    "    count_dict[\"c\"] = pileup_string.count(\"c\")\n",
    "    count_dict[\"g\"] = pileup_string.count(\"g\")\n",
    "\n",
    "    # get number of matches (determine where to count matches bases on ref_base)\n",
    "    n_matches = pileup_string.count('.') + pileup_string.count(',')\n",
    "    count_dict[ref_base] = n_matches\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "def get_relative_count(count_dict: dict[int], n_reads: int) -> dict[float]:\n",
    "    \"\"\"\n",
    "    Gets a dictionary containing the absolute counts for A, C, G and T \n",
    "    and calculates the relative proportions\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    count_dict : dict[int]\n",
    "        Dictionary containing the absolute counts for A, C, G and T\n",
    "    n_reads : int\n",
    "        Number of reads at the given position\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[float]\n",
    "        Dictionary containing the relative counts for A, C, G and T\n",
    "    \"\"\"\n",
    "    try:\n",
    "        count_dict[\"a_rel\"] = count_dict[\"a\"] / n_reads\n",
    "        count_dict[\"c_rel\"] = count_dict[\"c\"] / n_reads\n",
    "        count_dict[\"g_rel\"] = count_dict[\"g\"] / n_reads\n",
    "        count_dict[\"t_rel\"] = count_dict[\"t\"] / n_reads\n",
    "    except ZeroDivisionError:\n",
    "        count_dict[\"a_rel\"] = 0\n",
    "        count_dict[\"c_rel\"] = 0\n",
    "        count_dict[\"g_rel\"] = 0\n",
    "        count_dict[\"t_rel\"] = 0\n",
    "\n",
    "    return count_dict\n",
    "\n",
    "def get_majority_base(count_dict: dict) -> str:\n",
    "    \"\"\"\n",
    "    Gets a dictionary containing the absolute counts for A, C, G and T and returns the\n",
    "    key of the one with the highest count.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    count_dict : dict\n",
    "        dictionary containing the absolute counts for A, C, G and T\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        Key from the dictionary corresponding to the largest value\n",
    "    \"\"\"\n",
    "    dict_subset = dict((k, count_dict[k]) for k in (\"a\", \"c\", \"g\", \"t\"))\n",
    "    return max(dict_subset, key = dict_subset.get).upper()\n",
    "\n",
    "def get_motif(chr: str, site: int, ref: str, k: int) -> str:\n",
    "    \"\"\"\n",
    "    Extracts the motif of k bases up- and downstream from a given chromosomal site.\n",
    "    Around the start and end of a refernce sequence the missing bases are filled with\n",
    "    Ns.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    chr : str\n",
    "        name of the chromosome\n",
    "    site : int\n",
    "        position on the chromosome (1-indexed)\n",
    "    ref : str\n",
    "        reference sequence for the given chromosome \n",
    "    k : int\n",
    "        number of bases to be regarded in both up- and downstream direction \n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        sequence of k bases around the center site\n",
    "    \"\"\" \n",
    "    idx = site-1\n",
    "    n_ref = len(ref)\n",
    "\n",
    "    if idx >= 0 and idx < n_ref:\n",
    "        idx_l = idx-k\n",
    "        idx_r = idx+k+1\n",
    "        # left overhang\n",
    "        if idx_l < 0:\n",
    "            len_overhang = abs(idx_l)\n",
    "            overhang = \"N\" * len_overhang\n",
    "            motif = overhang + ref[:idx_r]\n",
    "        # right overhang\n",
    "        elif idx_r > n_ref:\n",
    "            len_overhang = idx_r - n_ref\n",
    "            overhang = \"N\" * len_overhang\n",
    "            motif = ref[idx_l:] + overhang\n",
    "        # no overhang\n",
    "        else:\n",
    "            motif = ref[idx_l:idx_r]\n",
    "\n",
    "        return motif\n",
    "    \n",
    "\n",
    "def get_allele_fraction(counts: dict, ref_base: str) -> int:\n",
    "    \"\"\"\n",
    "    Calculates the number of mismatched reads\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    counts : dict\n",
    "        Dictionary containing the number of occurences of A,C,G,T for a given position\n",
    "    ref_base : str\n",
    "        reference base at the given position\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    int\n",
    "        Number of mismatched reads a the given position\n",
    "    \"\"\"\n",
    "\n",
    "    mismatch_count_sum = 0\n",
    "    for b in [\"a\", \"c\", \"g\", \"t\"]:\n",
    "        if b != ref_base.lower():\n",
    "            mismatch_count_sum += counts[b+\"_rel\"]\n",
    "\n",
    "    return mismatch_count_sum\n",
    "\n",
    "\n",
    "def is_consensus_mismatch(threshold: float, counts: dict, n_reads: int, ref_base: str) -> bool:\n",
    "    \"\"\"\n",
    "    At a given position, checks if the number of mismatched reads exceeds the given threshold.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    threshold : float\n",
    "        Corresponds to the percentage of mismatched reads that are \n",
    "        allowed before returning True\n",
    "    counts : dict\n",
    "        Dictionary containing the number of occurences of A,C,G,T for a given position\n",
    "    n_reads : int\n",
    "        Number of reads at the given position\n",
    "    ref_base : str\n",
    "        reference base at the given position\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    bool\n",
    "        Does the number of mismatches at the position exceed the threshold? \n",
    "\n",
    "    \"\"\"\n",
    "    threshold = threshold * n_reads\n",
    "    mismatch_count_sum = get_allele_fraction(counts, ref_base)\n",
    "    return mismatch_count_sum >= threshold\n",
    "\n",
    "\n",
    "def get_read_quality(read_qualities: str) -> tuple[float, float]:\n",
    "    \"\"\"\n",
    "    Calculates the mean and std from the read qualities given in the sixth row\n",
    "    of a pileup file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    read_qualities : str\n",
    "        Read quality string from pileup file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    tuple[float, float]\n",
    "        Mean and standard deviation of read qualities\n",
    "    \"\"\"\n",
    "    # transform string to list of corresponding phred numeric values\n",
    "    vals = [code - 33 for code in read_qualities.encode(\"ascii\")]\n",
    "\n",
    "    mean = sum(vals)/len(vals)\n",
    "    std = np.std(vals)\n",
    "\n",
    "    return mean, std \n",
    "\n",
    "\n",
    "def get_references(path: str) -> dict[str]:\n",
    "    \"\"\"\n",
    "    Reads a fasta file and stores it in a dictionary.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    path : str\n",
    "        filepath to a fasta file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    dict[str]\n",
    "        Dictionary where the key is the chromosome name and the value is the sequence\n",
    "    \"\"\"\n",
    "    with open(path, \"r\") as ref:\n",
    "        lines = ref.readlines()\n",
    "        i = 0\n",
    "        refs = {}\n",
    "        for i in range(len(lines)):\n",
    "            line = lines[i]\n",
    "            if line.startswith(\">\"):\n",
    "                refs[line[1:].strip()] = lines[i+1].strip()\n",
    "        \n",
    "    return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_position(line: list[str]) -> str:\n",
    "    \"\"\"\n",
    "    Takes a line from a pileup file and processes it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    line : list[str]\n",
    "        list containing each element from the pileup line.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        New line derived from the initial one. Can be written to a new file in consequent\n",
    "        steps.\n",
    "    \"\"\"\n",
    "    # extract elements from list\n",
    "    chr, site, ref_base, n_reads, read_bases, read_qualities = line[0], int(line[1]), line[2], int(line[3]), line[4], line[5]\n",
    "    \n",
    "    # get reference sequence \n",
    "    ref = refs[chr]\n",
    "    # get absolute number of A, C, G, T, ins, del\n",
    "    count = parse_pileup_string(read_bases, ref_base)\n",
    "\n",
    "    # get relative number of A, C, G and T counts\n",
    "    count = get_relative_count(count, n_reads)\n",
    "\n",
    "    # get majority base\n",
    "    majority_base = get_majority_base(count)\n",
    "\n",
    "    # get 11b motif\n",
    "    motif = get_motif(chr, site, ref, k=5)\n",
    "\n",
    "    # get allele fraction\n",
    "    allele_fraction = get_allele_fraction(count, ref_base)\n",
    "\n",
    "    # get qualitiy measures\n",
    "    quality_mean, quality_std = get_read_quality(read_qualities)\n",
    "\n",
    "    out = f'{chr}\\t{site}\\t{n_reads}\\t{ref_base}\\t{majority_base}\\t{count[\"a\"]}\\t{count[\"c\"]}\\t{count[\"g\"]}\\t{count[\"t\"]}\\t{count[\"a_rel\"]}\\t{count[\"c_rel\"]}\\t{count[\"g_rel\"]}\\t{count[\"t_rel\"]}\\t{motif}\\t{allele_fraction}\\t{quality_mean}\\t{quality_std}\\n'\n",
    "    return out\n",
    "\n",
    "def process_file(infile: str, outfile: str, ref: str):\n",
    "    \"\"\"\n",
    "    Reads .pileup file and processes it, writing the results to a new file.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    infile : str\n",
    "        path to the input .pileup file\n",
    "    outfile : str\n",
    "        path to the output tsv file\n",
    "    ref : str\n",
    "        path to the reference fasta\n",
    "        \n",
    "    Returns\n",
    "    -------\n",
    "    None\n",
    "    \"\"\"\n",
    "    refs = get_references(ref)\n",
    "\n",
    "    with open(infile, \"r\") as i:\n",
    "        lines = i.readlines()\n",
    "\n",
    "        with open(outfile, \"w\") as o:\n",
    "            header = f\"chr\\tsite\\tn_reads\\tref_base\\tmajority_base\\tn_a\\tn_c\\tn_g\\tn_t\\tn_a_rel\\tn_c_rel\\tn_g_rel\\tn_t_rel\\tmotif\\tperc_mismatched\\tq_mean\\tq_std\\n\"\n",
    "            o.write(header)\n",
    "            for line in lines:\n",
    "                outline = process_position(line.split(\"\\t\"))\n",
    "                o.write(outline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = get_references(\"./Oligo_ref.fa\")\n",
    "process_file(\"./Oligo_1.pileup\", \"./Oligo_1_out.tsv\", \"./Oligo_ref.fa\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "refs = get_references(\"./curlcake_ref.fa\")\n",
    "process_file(\"./curlcake_m6a.pileup\", \"./curlcake_m6a_out.tsv\", \"./curlcake_ref.fa\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "masterthesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
